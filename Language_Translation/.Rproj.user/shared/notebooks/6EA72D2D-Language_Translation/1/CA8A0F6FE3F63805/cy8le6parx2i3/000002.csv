"0","text_sentences = c('The quick brown fox jumps over the lazy dog .',"
"0","    'By Jove , my quick study of lexicography won a prize .',"
"0","    'This is a short sentence .')"
"0","token_index <- length(text_sentences) + 1"
"0","output <- tokenize(text_sentences)"
"2","Loaded Tensorflow version 2.8.0
"
"0","text_tokenized <- output[1:length(text_sentences)]"
"0","# print(output)"
"0",""
"0","# Finding out the integer allocation to each word"
"0","tk <- output[[token_index]]$word_index"
"0","# print(tk)"
"0","# print(length(tk))"
"0","# print(table(tk))"
