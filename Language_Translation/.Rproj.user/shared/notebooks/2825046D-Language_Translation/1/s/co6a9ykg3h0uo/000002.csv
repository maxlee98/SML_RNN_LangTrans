"0","n <- nrow(train) #1000"
"0","train_x <- list(train[, 1])[[1]][1:n]"
"0","train_y <- list(train[, 2])[[1]][1:n]"
"0","# print(train_x)"
"0",""
"0","process_output <- preprocess_text(train_x, train_y)"
"0","# print(process_output[4],)"
"0","preprocess_x <- process_output[1]; preprocess_y <- process_output[2]; x_tk <- process_output[3]; y_tk <- process_output[4]"
"0","# print(preprocess_x[[1]])"
"0","# print(preprocess_y[[1]])"
"0",""
"0",""
"0","# Conversion back to list of words from tokenized word list"
"0","# attributes(x_tk[[1]])$names"
"0","# length(y_tk[[1]])"
