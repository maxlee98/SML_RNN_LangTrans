"0","n <- 1000"
"0","word_list <- list(train[, 2])[[1]][1:n]"
"0","new_output <- tokenize(word_list)"
"0","new_text_tokenized <- new_output[1:n]"
"0","new_padded_text <- pad(new_text_tokenized)"
"0",""
"0","# for(i in 1:n){"
"0","#   print(paste0(""Sequence in Text "", i, "":""))"
"0","#   print(paste0(""Input: "", word_list[i]))"
"0","#   print(paste0(""Output: "", list(new_text_tokenized[[i]])))"
"0","#   print(paste0(""Output (Padded): "", list(new_padded_text[i,])))"
"0","# }"
"0",""
